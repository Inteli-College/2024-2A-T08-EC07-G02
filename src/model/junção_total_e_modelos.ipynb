{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (2.1.0)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.4.0%2Bcpu-cp312-cp312-linux_x86_64.whl (195.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.0/195.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.19.0%2Bcpu-cp312-cp312-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.4.0%2Bcpu-cp312-cp312-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jinja2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setuptools (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m863.4/863.4 kB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from torchvision) (2.1.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, setuptools, pillow, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 pillow-10.2.0 setuptools-70.0.0 sympy-1.12 torch-2.4.0+cpu torchaudio-2.4.0+cpu torchvision-0.19.0+cpu typing-extensions-4.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn matplotlib\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os dataframes\n",
    "BASE_PATH = \"temp/\"\n",
    "falhas = pd.read_csv(f'{BASE_PATH}/PREDICTS_FINAIS.csv')\n",
    "resultados = pd.read_csv(f'{BASE_PATH}/RESULTADOS_FINALMENTE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>FALHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-0436112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-0436064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-0436473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-0436117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-0436069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>2024-3256276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>2024-3256284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>2024-3316245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>2024-2036106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>2024-2056103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7916 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               KNR  FALHA\n",
       "0     2023-0436112      1\n",
       "1     2023-0436064      1\n",
       "2     2023-0436473      1\n",
       "3     2023-0436117      1\n",
       "4     2023-0436069      1\n",
       "...            ...    ...\n",
       "7911  2024-3256276      1\n",
       "7912  2024-3256284      1\n",
       "7913  2024-3316245      1\n",
       "7914  2024-2036106      1\n",
       "7915  2024-2056103      1\n",
       "\n",
       "[7916 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualização do dataframe de falhas final\n",
    "falhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>ID1NAME</th>\n",
       "      <th>ID1SOK</th>\n",
       "      <th>ID1SNOK</th>\n",
       "      <th>ID1DATA</th>\n",
       "      <th>ID2NAME</th>\n",
       "      <th>ID2SOK</th>\n",
       "      <th>ID2SNOK</th>\n",
       "      <th>ID2DATA</th>\n",
       "      <th>ID718NAME</th>\n",
       "      <th>ID718SOK</th>\n",
       "      <th>ID718SNOK</th>\n",
       "      <th>ID718DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2016173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2026098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.133866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2026162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2026175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.751412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2026215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.212350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79396</th>\n",
       "      <td>2024-2976009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79397</th>\n",
       "      <td>2024-2976010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79398</th>\n",
       "      <td>2024-2976011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79399</th>\n",
       "      <td>2024-2976012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.293958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79400</th>\n",
       "      <td>2024-2976013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79401 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNR  ID1NAME  ID1SOK  ID1SNOK  ID1DATA  ID2NAME  ID2SOK  \\\n",
       "0      2023-2016173      0.0     0.0      0.0      0.0     12.0    12.0   \n",
       "1      2023-2026098      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "2      2023-2026162      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "3      2023-2026175      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "4      2023-2026215      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "...             ...      ...     ...      ...      ...      ...     ...   \n",
       "79396  2024-2976009      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "79397  2024-2976010      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "79398  2024-2976011      0.0     0.0      0.0      0.0     74.0    74.0   \n",
       "79399  2024-2976012      0.0     0.0      0.0      0.0     82.0    82.0   \n",
       "79400  2024-2976013      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "\n",
       "       ID2SNOK   ID2DATA  ID718NAME  ID718SOK  ID718SNOK  ID718DATA  \n",
       "0          0.0  0.000231       11.0      10.0        1.0   0.213692  \n",
       "1          0.0  0.000012       15.0      13.0        2.0   0.133866  \n",
       "2          0.0  0.000058       11.0      11.0        0.0   0.046956  \n",
       "3          0.0  0.000069       19.0      14.0        5.0   0.751412  \n",
       "4          0.0  0.000058       19.0      15.0        4.0   3.212350  \n",
       "...        ...       ...        ...       ...        ...        ...  \n",
       "79396      0.0  0.045683        0.0       0.0        0.0   0.000000  \n",
       "79397      0.0  0.059190        0.0       0.0        0.0   0.000000  \n",
       "79398      0.0  0.089086        0.0       0.0        0.0   0.000000  \n",
       "79399      0.0  4.293958        0.0       0.0        0.0   0.000000  \n",
       "79400      0.0  0.054491        0.0       0.0        0.0   0.000000  \n",
       "\n",
       "[79401 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preenchendo os valores nulos com 0 no dataframe de resultados\n",
    "resultado_df = resultados.fillna(0)\n",
    "resultado_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>ID1NAME</th>\n",
       "      <th>ID1SOK</th>\n",
       "      <th>ID1SNOK</th>\n",
       "      <th>ID1DATA</th>\n",
       "      <th>ID2NAME</th>\n",
       "      <th>ID2SOK</th>\n",
       "      <th>ID2SNOK</th>\n",
       "      <th>ID2DATA</th>\n",
       "      <th>ID718NAME</th>\n",
       "      <th>ID718SOK</th>\n",
       "      <th>ID718SNOK</th>\n",
       "      <th>ID718DATA</th>\n",
       "      <th>FALHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2016173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2026098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2026162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2026175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.751412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2026215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.212350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79396</th>\n",
       "      <td>2024-2976009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79397</th>\n",
       "      <td>2024-2976010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79398</th>\n",
       "      <td>2024-2976011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79399</th>\n",
       "      <td>2024-2976012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.293958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79400</th>\n",
       "      <td>2024-2976013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79401 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNR  ID1NAME  ID1SOK  ID1SNOK  ID1DATA  ID2NAME  ID2SOK  \\\n",
       "0      2023-2016173      0.0     0.0      0.0      0.0     12.0    12.0   \n",
       "1      2023-2026098      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "2      2023-2026162      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "3      2023-2026175      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "4      2023-2026215      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "...             ...      ...     ...      ...      ...      ...     ...   \n",
       "79396  2024-2976009      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "79397  2024-2976010      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "79398  2024-2976011      0.0     0.0      0.0      0.0     74.0    74.0   \n",
       "79399  2024-2976012      0.0     0.0      0.0      0.0     82.0    82.0   \n",
       "79400  2024-2976013      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "\n",
       "       ID2SNOK   ID2DATA  ID718NAME  ID718SOK  ID718SNOK  ID718DATA  FALHA  \n",
       "0          0.0  0.000231       11.0      10.0        1.0   0.213692      0  \n",
       "1          0.0  0.000012       15.0      13.0        2.0   0.133866      0  \n",
       "2          0.0  0.000058       11.0      11.0        0.0   0.046956      0  \n",
       "3          0.0  0.000069       19.0      14.0        5.0   0.751412      0  \n",
       "4          0.0  0.000058       19.0      15.0        4.0   3.212350      0  \n",
       "...        ...       ...        ...       ...        ...        ...    ...  \n",
       "79396      0.0  0.045683        0.0       0.0        0.0   0.000000      0  \n",
       "79397      0.0  0.059190        0.0       0.0        0.0   0.000000      0  \n",
       "79398      0.0  0.089086        0.0       0.0        0.0   0.000000      0  \n",
       "79399      0.0  4.293958        0.0       0.0        0.0   0.000000      0  \n",
       "79400      0.0  0.054491        0.0       0.0        0.0   0.000000      0  \n",
       "\n",
       "[79401 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionando a coluna de falhas ao dataframe de resultados\n",
    "resultado_df['FALHA'] = 0\n",
    "resultado_df['FALHA'] = resultado_df['FALHA'].astype(int)\n",
    "resultado_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>ID1NAME</th>\n",
       "      <th>ID1SOK</th>\n",
       "      <th>ID1SNOK</th>\n",
       "      <th>ID1DATA</th>\n",
       "      <th>ID2NAME</th>\n",
       "      <th>ID2SOK</th>\n",
       "      <th>ID2SNOK</th>\n",
       "      <th>ID2DATA</th>\n",
       "      <th>ID718NAME</th>\n",
       "      <th>ID718SOK</th>\n",
       "      <th>ID718SNOK</th>\n",
       "      <th>ID718DATA</th>\n",
       "      <th>FALHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2016173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2026098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2026162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2026175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.751412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2026215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.212350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79396</th>\n",
       "      <td>2024-2976009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79397</th>\n",
       "      <td>2024-2976010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79398</th>\n",
       "      <td>2024-2976011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79399</th>\n",
       "      <td>2024-2976012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.293958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79400</th>\n",
       "      <td>2024-2976013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79401 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNR  ID1NAME  ID1SOK  ID1SNOK  ID1DATA  ID2NAME  ID2SOK  \\\n",
       "0      2023-2016173      0.0     0.0      0.0      0.0     12.0    12.0   \n",
       "1      2023-2026098      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "2      2023-2026162      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "3      2023-2026175      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "4      2023-2026215      0.0     0.0      0.0      0.0      8.0     8.0   \n",
       "...             ...      ...     ...      ...      ...      ...     ...   \n",
       "79396  2024-2976009      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "79397  2024-2976010      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "79398  2024-2976011      0.0     0.0      0.0      0.0     74.0    74.0   \n",
       "79399  2024-2976012      0.0     0.0      0.0      0.0     82.0    82.0   \n",
       "79400  2024-2976013      0.0     0.0      0.0      0.0     72.0    72.0   \n",
       "\n",
       "       ID2SNOK   ID2DATA  ID718NAME  ID718SOK  ID718SNOK  ID718DATA  FALHA  \n",
       "0          0.0  0.000231       11.0      10.0        1.0   0.213692      0  \n",
       "1          0.0  0.000012       15.0      13.0        2.0   0.133866      1  \n",
       "2          0.0  0.000058       11.0      11.0        0.0   0.046956      0  \n",
       "3          0.0  0.000069       19.0      14.0        5.0   0.751412      0  \n",
       "4          0.0  0.000058       19.0      15.0        4.0   3.212350      0  \n",
       "...        ...       ...        ...       ...        ...        ...    ...  \n",
       "79396      0.0  0.045683        0.0       0.0        0.0   0.000000      0  \n",
       "79397      0.0  0.059190        0.0       0.0        0.0   0.000000      0  \n",
       "79398      0.0  0.089086        0.0       0.0        0.0   0.000000      0  \n",
       "79399      0.0  4.293958        0.0       0.0        0.0   0.000000      0  \n",
       "79400      0.0  0.054491        0.0       0.0        0.0   0.000000      0  \n",
       "\n",
       "[79401 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntando a coluna de falhas do dataframe de falhas ao dataframe de resultados\n",
    "resultado_df.loc[resultado_df['KNR'].isin(falhas['KNR']), 'FALHA'] = 1\n",
    "resultado_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALHA\n",
       "0    74372\n",
       "1     5029\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a quantidade de falhas e não falhas\n",
    "resultado_df['FALHA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>ID1NAME</th>\n",
       "      <th>ID1SOK</th>\n",
       "      <th>ID1SNOK</th>\n",
       "      <th>ID1DATA</th>\n",
       "      <th>ID2NAME</th>\n",
       "      <th>ID2SOK</th>\n",
       "      <th>ID2SNOK</th>\n",
       "      <th>ID2DATA</th>\n",
       "      <th>ID718NAME</th>\n",
       "      <th>ID718SOK</th>\n",
       "      <th>ID718SNOK</th>\n",
       "      <th>ID718DATA</th>\n",
       "      <th>FALHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2016173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.389356e-06</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2026098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.946779e-08</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.034946</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2026162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.473390e-07</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2026175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.168068e-07</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2026215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.473390e-07</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.00396</td>\n",
       "      <td>0.040083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79396</th>\n",
       "      <td>2024-2976009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.741894e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79397</th>\n",
       "      <td>2024-2976010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.552583e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79398</th>\n",
       "      <td>2024-2976011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0.034023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.346936e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79399</th>\n",
       "      <td>2024-2976012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035637</td>\n",
       "      <td>0.037701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.577241e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79400</th>\n",
       "      <td>2024-2976013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.270544e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79401 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNR  ID1NAME  ID1SOK  ID1SNOK  ID1DATA   ID2NAME    ID2SOK  \\\n",
       "0      2023-2016173      0.0     0.0      0.0      0.0  0.005215  0.005517   \n",
       "1      2023-2026098      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "2      2023-2026162      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "3      2023-2026175      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "4      2023-2026215      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "...             ...      ...     ...      ...      ...       ...       ...   \n",
       "79396  2024-2976009      0.0     0.0      0.0      0.0  0.031291  0.033103   \n",
       "79397  2024-2976010      0.0     0.0      0.0      0.0  0.031291  0.033103   \n",
       "79398  2024-2976011      0.0     0.0      0.0      0.0  0.032160  0.034023   \n",
       "79399  2024-2976012      0.0     0.0      0.0      0.0  0.035637  0.037701   \n",
       "79400  2024-2976013      0.0     0.0      0.0      0.0  0.031291  0.033103   \n",
       "\n",
       "       ID2SNOK       ID2DATA  ID718NAME  ID718SOK  ID718SNOK  ID718DATA  FALHA  \n",
       "0          0.0  1.389356e-06   0.009205  0.026882    0.00099   0.002666      0  \n",
       "1          0.0  6.946779e-08   0.012552  0.034946    0.00198   0.001670      1  \n",
       "2          0.0  3.473390e-07   0.009205  0.029570    0.00000   0.000586      0  \n",
       "3          0.0  4.168068e-07   0.015900  0.037634    0.00495   0.009376      0  \n",
       "4          0.0  3.473390e-07   0.015900  0.040323    0.00396   0.040083      0  \n",
       "...        ...           ...        ...       ...        ...        ...    ...  \n",
       "79396      0.0  2.741894e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79397      0.0  3.552583e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79398      0.0  5.346936e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79399      0.0  2.577241e-02   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79400      0.0  3.270544e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "\n",
       "[79401 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizando os dados \n",
    "colunas_numericas = resultado_df.columns.difference(['KNR', 'FALHA'])\n",
    "\n",
    "resultado_normalizado = resultado_df.copy()\n",
    "\n",
    "resultado_normalizado[colunas_numericas] = (resultado_df[colunas_numericas] - resultado_df[colunas_numericas].min()) / (resultado_df[colunas_numericas].max() - resultado_df[colunas_numericas].min())\n",
    "\n",
    "resultado_normalizado = resultado_normalizado.fillna(0)\n",
    "resultado_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>ID1NAME</th>\n",
       "      <th>ID1SOK</th>\n",
       "      <th>ID1SNOK</th>\n",
       "      <th>ID1DATA</th>\n",
       "      <th>ID2NAME</th>\n",
       "      <th>ID2SOK</th>\n",
       "      <th>ID2SNOK</th>\n",
       "      <th>ID2DATA</th>\n",
       "      <th>ID718NAME</th>\n",
       "      <th>ID718SOK</th>\n",
       "      <th>ID718SNOK</th>\n",
       "      <th>ID718DATA</th>\n",
       "      <th>FALHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2016173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.389356e-06</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2026098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.946779e-08</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.034946</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2026162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.473390e-07</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2026175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.168068e-07</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2026215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.473390e-07</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.00396</td>\n",
       "      <td>0.040083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79396</th>\n",
       "      <td>2024-2976009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.741894e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79397</th>\n",
       "      <td>2024-2976010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.552583e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79398</th>\n",
       "      <td>2024-2976011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0.034023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.346936e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79399</th>\n",
       "      <td>2024-2976012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035637</td>\n",
       "      <td>0.037701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.577241e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79400</th>\n",
       "      <td>2024-2976013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.270544e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79401 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNR  ID1NAME  ID1SOK  ID1SNOK  ID1DATA   ID2NAME    ID2SOK  \\\n",
       "0      2023-2016173      0.0     0.0      0.0      0.0  0.005215  0.005517   \n",
       "1      2023-2026098      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "2      2023-2026162      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "3      2023-2026175      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "4      2023-2026215      0.0     0.0      0.0      0.0  0.003477  0.003678   \n",
       "...             ...      ...     ...      ...      ...       ...       ...   \n",
       "79396  2024-2976009      0.0     0.0      0.0      0.0  0.031291  0.033103   \n",
       "79397  2024-2976010      0.0     0.0      0.0      0.0  0.031291  0.033103   \n",
       "79398  2024-2976011      0.0     0.0      0.0      0.0  0.032160  0.034023   \n",
       "79399  2024-2976012      0.0     0.0      0.0      0.0  0.035637  0.037701   \n",
       "79400  2024-2976013      0.0     0.0      0.0      0.0  0.031291  0.033103   \n",
       "\n",
       "       ID2SNOK       ID2DATA  ID718NAME  ID718SOK  ID718SNOK  ID718DATA  FALHA  \n",
       "0          0.0  1.389356e-06   0.009205  0.026882    0.00099   0.002666      0  \n",
       "1          0.0  6.946779e-08   0.012552  0.034946    0.00198   0.001670      1  \n",
       "2          0.0  3.473390e-07   0.009205  0.029570    0.00000   0.000586      0  \n",
       "3          0.0  4.168068e-07   0.015900  0.037634    0.00495   0.009376      0  \n",
       "4          0.0  3.473390e-07   0.015900  0.040323    0.00396   0.040083      0  \n",
       "...        ...           ...        ...       ...        ...        ...    ...  \n",
       "79396      0.0  2.741894e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79397      0.0  3.552583e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79398      0.0  5.346936e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79399      0.0  2.577241e-02   0.000000  0.000000    0.00000   0.000000      0  \n",
       "79400      0.0  3.270544e-04   0.000000  0.000000    0.00000   0.000000      0  \n",
       "\n",
       "[79401 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preenchendo os valores nulos com 0 no dataframe final pela última vez\n",
    "resultado_normalizado.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando os dados da coluna \"FALHA\" do dataframe final\n",
    "resultado_normalizado['FALHA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicioslugli/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vinicioslugli/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vinicioslugli/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     23\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred)\n\u001b[0;32m---> 25\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:328\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    314\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    318\u001b[0m (\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 328\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Supondo que 'resultado_normalizado' já está normalizado e disponível\n",
    "# Preparação dos dados\n",
    "X = resultado_normalizado.drop(columns=['KNR', 'FALHA'])  # Features: todas as colunas exceto 'KNR' e 'FALHA'\n",
    "y = resultado_normalizado['FALHA']  # Target: coluna 'FALHA'\n",
    "\n",
    "# Divisão em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinamento do modelo SVM\n",
    "svm_model = SVC(kernel='rbf')  # Usando kernel RBF como exemplo\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predição no conjunto de teste\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Avaliação do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "cv_scores = cross_val_score(svm_model, X, y, cv=5)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV score: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352252214432644\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     22281\n",
      "           1       0.33      0.00      0.00      1540\n",
      "\n",
      "    accuracy                           0.94     23821\n",
      "   macro avg       0.63      0.50      0.49     23821\n",
      "weighted avg       0.90      0.94      0.90     23821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Supondo que 'resultado_normalizado' já está normalizado e disponível\n",
    "# Preparação dos dados\n",
    "X = resultado_normalizado.drop(columns=['KNR', 'FALHA'])  # Features: todas as colunas exceto 'KNR' e 'FALHA'\n",
    "y = resultado_normalizado['FALHA']  # Target: coluna 'FALHA'\n",
    "\n",
    "# Divisão em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Criação e treinamento do modelo Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predição no conjunto de teste\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Avaliação do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9335684150872111\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     14854\n",
      "           1       0.20      0.01      0.02      1027\n",
      "\n",
      "    accuracy                           0.93     15881\n",
      "   macro avg       0.57      0.50      0.49     15881\n",
      "weighted avg       0.89      0.93      0.90     15881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Selecionar features e target\n",
    "X = resultado_normalizado.drop(columns=['KNR', 'FALHA'])\n",
    "y = resultado_normalizado['FALHA']\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões e avaliar o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Rede Neural Recorrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.6669394373893738\n",
      "Epoch 2/200, Loss: 0.6600790023803711\n",
      "Epoch 3/200, Loss: 0.6532943844795227\n",
      "Epoch 4/200, Loss: 0.6465845108032227\n",
      "Epoch 5/200, Loss: 0.639948844909668\n",
      "Epoch 6/200, Loss: 0.6333866119384766\n",
      "Epoch 7/200, Loss: 0.6268970370292664\n",
      "Epoch 8/200, Loss: 0.6204782724380493\n",
      "Epoch 9/200, Loss: 0.6141282916069031\n",
      "Epoch 10/200, Loss: 0.6078449487686157\n",
      "Epoch 11/200, Loss: 0.6016261577606201\n",
      "Epoch 12/200, Loss: 0.5954698324203491\n",
      "Epoch 13/200, Loss: 0.5893732905387878\n",
      "Epoch 14/200, Loss: 0.5833345055580139\n",
      "Epoch 15/200, Loss: 0.5773506760597229\n",
      "Epoch 16/200, Loss: 0.5714196562767029\n",
      "Epoch 17/200, Loss: 0.5655391216278076\n",
      "Epoch 18/200, Loss: 0.55970698595047\n",
      "Epoch 19/200, Loss: 0.5539215207099915\n",
      "Epoch 20/200, Loss: 0.5481809377670288\n",
      "Epoch 21/200, Loss: 0.5424841642379761\n",
      "Epoch 22/200, Loss: 0.5368297100067139\n",
      "Epoch 23/200, Loss: 0.5312166213989258\n",
      "Epoch 24/200, Loss: 0.5256438851356506\n",
      "Epoch 25/200, Loss: 0.520110547542572\n",
      "Epoch 26/200, Loss: 0.5146160125732422\n",
      "Epoch 27/200, Loss: 0.509159505367279\n",
      "Epoch 28/200, Loss: 0.5037404894828796\n",
      "Epoch 29/200, Loss: 0.4983585476875305\n",
      "Epoch 30/200, Loss: 0.4930133819580078\n",
      "Epoch 31/200, Loss: 0.48770496249198914\n",
      "Epoch 32/200, Loss: 0.48243358731269836\n",
      "Epoch 33/200, Loss: 0.4771995544433594\n",
      "Epoch 34/200, Loss: 0.4720035195350647\n",
      "Epoch 35/200, Loss: 0.4668462872505188\n",
      "Epoch 36/200, Loss: 0.4617287218570709\n",
      "Epoch 37/200, Loss: 0.4566519856452942\n",
      "Epoch 38/200, Loss: 0.45161715149879456\n",
      "Epoch 39/200, Loss: 0.44662541151046753\n",
      "Epoch 40/200, Loss: 0.4416780173778534\n",
      "Epoch 41/200, Loss: 0.43677619099617004\n",
      "Epoch 42/200, Loss: 0.431921124458313\n",
      "Epoch 43/200, Loss: 0.4271140992641449\n",
      "Epoch 44/200, Loss: 0.42235639691352844\n",
      "Epoch 45/200, Loss: 0.4176492989063263\n",
      "Epoch 46/200, Loss: 0.4129941165447235\n",
      "Epoch 47/200, Loss: 0.4083921015262604\n",
      "Epoch 48/200, Loss: 0.4038446247577667\n",
      "Epoch 49/200, Loss: 0.3993529975414276\n",
      "Epoch 50/200, Loss: 0.3949185311794281\n",
      "Epoch 51/200, Loss: 0.3905424475669861\n",
      "Epoch 52/200, Loss: 0.38622602820396423\n",
      "Epoch 53/200, Loss: 0.3819705545902252\n",
      "Epoch 54/200, Loss: 0.37777724862098694\n",
      "Epoch 55/200, Loss: 0.3736473321914673\n",
      "Epoch 56/200, Loss: 0.3695819675922394\n",
      "Epoch 57/200, Loss: 0.36558231711387634\n",
      "Epoch 58/200, Loss: 0.36164939403533936\n",
      "Epoch 59/200, Loss: 0.3577842712402344\n",
      "Epoch 60/200, Loss: 0.3539879024028778\n",
      "Epoch 61/200, Loss: 0.3502611517906189\n",
      "Epoch 62/200, Loss: 0.34660470485687256\n",
      "Epoch 63/200, Loss: 0.34301936626434326\n",
      "Epoch 64/200, Loss: 0.33950576186180115\n",
      "Epoch 65/200, Loss: 0.3360643684864044\n",
      "Epoch 66/200, Loss: 0.3326956033706665\n",
      "Epoch 67/200, Loss: 0.32939982414245605\n",
      "Epoch 68/200, Loss: 0.32617729902267456\n",
      "Epoch 69/200, Loss: 0.32302817702293396\n",
      "Epoch 70/200, Loss: 0.3199526369571686\n",
      "Epoch 71/200, Loss: 0.31695058941841125\n",
      "Epoch 72/200, Loss: 0.3140219449996948\n",
      "Epoch 73/200, Loss: 0.3111666142940521\n",
      "Epoch 74/200, Loss: 0.30838432908058167\n",
      "Epoch 75/200, Loss: 0.30567479133605957\n",
      "Epoch 76/200, Loss: 0.30303755402565\n",
      "Epoch 77/200, Loss: 0.3004721701145172\n",
      "Epoch 78/200, Loss: 0.29797816276550293\n",
      "Epoch 79/200, Loss: 0.2955547869205475\n",
      "Epoch 80/200, Loss: 0.2932014465332031\n",
      "Epoch 81/200, Loss: 0.29091736674308777\n",
      "Epoch 82/200, Loss: 0.28870171308517456\n",
      "Epoch 83/200, Loss: 0.2865535020828247\n",
      "Epoch 84/200, Loss: 0.28447192907333374\n",
      "Epoch 85/200, Loss: 0.2824558913707733\n",
      "Epoch 86/200, Loss: 0.2805043160915375\n",
      "Epoch 87/200, Loss: 0.27861618995666504\n",
      "Epoch 88/200, Loss: 0.2767903804779053\n",
      "Epoch 89/200, Loss: 0.2750256061553955\n",
      "Epoch 90/200, Loss: 0.273320734500885\n",
      "Epoch 91/200, Loss: 0.2716745436191559\n",
      "Epoch 92/200, Loss: 0.27008575201034546\n",
      "Epoch 93/200, Loss: 0.26855307817459106\n",
      "Epoch 94/200, Loss: 0.26707524061203003\n",
      "Epoch 95/200, Loss: 0.2656508982181549\n",
      "Epoch 96/200, Loss: 0.2642786502838135\n",
      "Epoch 97/200, Loss: 0.26295730471611023\n",
      "Epoch 98/200, Loss: 0.26168549060821533\n",
      "Epoch 99/200, Loss: 0.2604617774486542\n",
      "Epoch 100/200, Loss: 0.2592848837375641\n",
      "Epoch 101/200, Loss: 0.25815343856811523\n",
      "Epoch 102/200, Loss: 0.25706619024276733\n",
      "Epoch 103/200, Loss: 0.2560217082500458\n",
      "Epoch 104/200, Loss: 0.2550187408924103\n",
      "Epoch 105/200, Loss: 0.25405603647232056\n",
      "Epoch 106/200, Loss: 0.2531322240829468\n",
      "Epoch 107/200, Loss: 0.25224608182907104\n",
      "Epoch 108/200, Loss: 0.25139638781547546\n",
      "Epoch 109/200, Loss: 0.25058189034461975\n",
      "Epoch 110/200, Loss: 0.249801367521286\n",
      "Epoch 111/200, Loss: 0.2490536868572235\n",
      "Epoch 112/200, Loss: 0.24833765625953674\n",
      "Epoch 113/200, Loss: 0.24765212833881378\n",
      "Epoch 114/200, Loss: 0.24699606001377106\n",
      "Epoch 115/200, Loss: 0.24636830389499664\n",
      "Epoch 116/200, Loss: 0.24576780200004578\n",
      "Epoch 117/200, Loss: 0.24519357085227966\n",
      "Epoch 118/200, Loss: 0.24464458227157593\n",
      "Epoch 119/200, Loss: 0.24411983788013458\n",
      "Epoch 120/200, Loss: 0.2436184287071228\n",
      "Epoch 121/200, Loss: 0.24313941597938538\n",
      "Epoch 122/200, Loss: 0.24268190562725067\n",
      "Epoch 123/200, Loss: 0.24224503338336945\n",
      "Epoch 124/200, Loss: 0.24182796478271484\n",
      "Epoch 125/200, Loss: 0.24142986536026\n",
      "Epoch 126/200, Loss: 0.24104994535446167\n",
      "Epoch 127/200, Loss: 0.2406875044107437\n",
      "Epoch 128/200, Loss: 0.24034178256988525\n",
      "Epoch 129/200, Loss: 0.2400120049715042\n",
      "Epoch 130/200, Loss: 0.23969757556915283\n",
      "Epoch 131/200, Loss: 0.23939774930477142\n",
      "Epoch 132/200, Loss: 0.23911195993423462\n",
      "Epoch 133/200, Loss: 0.23883956670761108\n",
      "Epoch 134/200, Loss: 0.23857997357845306\n",
      "Epoch 135/200, Loss: 0.2383326292037964\n",
      "Epoch 136/200, Loss: 0.23809696733951569\n",
      "Epoch 137/200, Loss: 0.23787246644496918\n",
      "Epoch 138/200, Loss: 0.23765866458415985\n",
      "Epoch 139/200, Loss: 0.23745499551296234\n",
      "Epoch 140/200, Loss: 0.23726102709770203\n",
      "Epoch 141/200, Loss: 0.23707638680934906\n",
      "Epoch 142/200, Loss: 0.23690050840377808\n",
      "Epoch 143/200, Loss: 0.23673304915428162\n",
      "Epoch 144/200, Loss: 0.23657365143299103\n",
      "Epoch 145/200, Loss: 0.23642191290855408\n",
      "Epoch 146/200, Loss: 0.23627741634845734\n",
      "Epoch 147/200, Loss: 0.23613987863063812\n",
      "Epoch 148/200, Loss: 0.23600894212722778\n",
      "Epoch 149/200, Loss: 0.23588430881500244\n",
      "Epoch 150/200, Loss: 0.23576562106609344\n",
      "Epoch 151/200, Loss: 0.23565265536308289\n",
      "Epoch 152/200, Loss: 0.2355450689792633\n",
      "Epoch 153/200, Loss: 0.235442653298378\n",
      "Epoch 154/200, Loss: 0.23534511029720306\n",
      "Epoch 155/200, Loss: 0.23525220155715942\n",
      "Epoch 156/200, Loss: 0.23516370356082916\n",
      "Epoch 157/200, Loss: 0.23507940769195557\n",
      "Epoch 158/200, Loss: 0.23499907553195953\n",
      "Epoch 159/200, Loss: 0.23492249846458435\n",
      "Epoch 160/200, Loss: 0.23484952747821808\n",
      "Epoch 161/200, Loss: 0.23477989435195923\n",
      "Epoch 162/200, Loss: 0.23471350967884064\n",
      "Epoch 163/200, Loss: 0.2346501648426056\n",
      "Epoch 164/200, Loss: 0.23458974063396454\n",
      "Epoch 165/200, Loss: 0.23453207314014435\n",
      "Epoch 166/200, Loss: 0.23447705805301666\n",
      "Epoch 167/200, Loss: 0.23442456126213074\n",
      "Epoch 168/200, Loss: 0.23437443375587463\n",
      "Epoch 169/200, Loss: 0.23432660102844238\n",
      "Epoch 170/200, Loss: 0.23428091406822205\n",
      "Epoch 171/200, Loss: 0.23423725366592407\n",
      "Epoch 172/200, Loss: 0.2341955155134201\n",
      "Epoch 173/200, Loss: 0.23415561020374298\n",
      "Epoch 174/200, Loss: 0.23411741852760315\n",
      "Epoch 175/200, Loss: 0.23408083617687225\n",
      "Epoch 176/200, Loss: 0.2340458333492279\n",
      "Epoch 177/200, Loss: 0.23401224613189697\n",
      "Epoch 178/200, Loss: 0.23398004472255707\n",
      "Epoch 179/200, Loss: 0.23394915461540222\n",
      "Epoch 180/200, Loss: 0.23391947150230408\n",
      "Epoch 181/200, Loss: 0.23389096558094025\n",
      "Epoch 182/200, Loss: 0.23386350274085999\n",
      "Epoch 183/200, Loss: 0.2338370531797409\n",
      "Epoch 184/200, Loss: 0.2338116317987442\n",
      "Epoch 185/200, Loss: 0.23378705978393555\n",
      "Epoch 186/200, Loss: 0.23376338183879852\n",
      "Epoch 187/200, Loss: 0.23374050855636597\n",
      "Epoch 188/200, Loss: 0.23371842503547668\n",
      "Epoch 189/200, Loss: 0.23369713127613068\n",
      "Epoch 190/200, Loss: 0.23367661237716675\n",
      "Epoch 191/200, Loss: 0.23365680873394012\n",
      "Epoch 192/200, Loss: 0.2336377203464508\n",
      "Epoch 193/200, Loss: 0.23361928761005402\n",
      "Epoch 194/200, Loss: 0.23360149562358856\n",
      "Epoch 195/200, Loss: 0.23358431458473206\n",
      "Epoch 196/200, Loss: 0.23356766998767853\n",
      "Epoch 197/200, Loss: 0.23355157673358917\n",
      "Epoch 198/200, Loss: 0.2335360050201416\n",
      "Epoch 199/200, Loss: 0.23352089524269104\n",
      "Epoch 200/200, Loss: 0.2335062474012375\n",
      "Accuracy: 0.9373465147031044\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97     14886\n",
      "         1.0       0.00      0.00      0.00       995\n",
      "\n",
      "    accuracy                           0.94     15881\n",
      "   macro avg       0.47      0.50      0.48     15881\n",
      "weighted avg       0.88      0.94      0.91     15881\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicioslugli/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vinicioslugli/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vinicioslugli/Documentos/scripts/inteli/2024-2A-T08-EC07-G02/src/model/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Selecionar features e target\n",
    "X = resultado_normalizado.drop(columns=['KNR', 'FALHA'])\n",
    "y = resultado_normalizado['FALHA']\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Converter para tensores\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Reshape necessário para o formato (batch_size, seq_len, num_features)\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_test = X_test.unsqueeze(1)\n",
    "\n",
    "# Definir a RNN\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# Parâmetros do modelo\n",
    "input_size = X_train.shape[2]\n",
    "\n",
    "hidden_size = 64\n",
    "output_size = 1  # Saída única, porque 'FALHA' é uma variável de saída binária\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.BCEWithLogitsLoss()  # Função de perda para classificação binária\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs.squeeze(), y_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Avaliar o modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).float()\n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    report = classification_report(y_test, predicted)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O KNR 2023-2026175 tem uma predição de: NÃO FALHA (probabilidade: 0.0738)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Selecionar os dados correspondentes ao KNR especificado\n",
    "knr = \"2023-2026175\"\n",
    "knr_data = resultado_normalizado[resultado_normalizado['KNR'] == knr]\n",
    "\n",
    "if knr_data.empty:\n",
    "    print(f'KNR {knr} não encontrado no dataset.')\n",
    "else:\n",
    "    # Preparar os dados\n",
    "    knr_features = knr_data.drop(columns=['KNR', 'FALHA'])\n",
    "\n",
    "    # Normalizar os dados usando o scaler ajustado previamente\n",
    "    knr_features = scaler.transform(knr_features)\n",
    "\n",
    "    # Converter para tensor\n",
    "    knr_features = torch.tensor(knr_features, dtype=torch.float32)\n",
    "\n",
    "    # Reshape necessário para o formato (batch_size, seq_len, num_features)\n",
    "    knr_features = knr_features.unsqueeze(1)\n",
    "\n",
    "    # Utilizar o modelo para realizar a predição\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(knr_features)\n",
    "        predicted = torch.sigmoid(output.squeeze()).item()\n",
    "        prediction = \"FALHA\" if predicted > 0.5 else \"NÃO FALHA\"\n",
    "\n",
    "    print(f'O KNR {knr} tem uma predição de: {prediction} (probabilidade: {predicted:.4f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
